import os
import time
from datetime import datetime

import streamlit as st
import torch
import torch.nn as nn
from torchvision import models
from PIL import Image

# í˜ì´ì§€ & ìŠ¤íƒ€ì¼
st.set_page_config(page_title="ìœ ëª¨ì°¨ ì¤‘ê³ ê±°ë˜ ê°€ê²© ì¶”ì²œ", page_icon="ğŸ¼", layout="centered")
st.markdown(
    """
    <style>
    
    .block-container {padding-top: 2rem; padding-bottom: 2rem;}
    
    h1 {font-weight: 800; letter-spacing: -0.3px;}
    
    div.stButton > button {
        width: 100%; height: 56px; font-size: 20px; font-weight: 700;
        background: #FF8A1E; color: white; border: none; border-radius: 8px;
    }
    
    div.stButton > button:hover {background: #ff9e45; color: white; border: none;}
    
    .card {background: #111111; padding: 24px; border-radius: 10px; margin-top: 16px; margin-bottom: 24px;}
    
    .card h3 {margin-top: 0; font-weight: 800; letter-spacing: -0.3px;}
    
    label, .stSelectbox label, .stNumberInput label, .stRadio label, label {
        font-weight: 800 !important; font-size: 18px !important;
    }
    
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown("<h1>ğŸ¼ ìœ ëª¨ì°¨ ì¤‘ê³ ê±°ë˜ ê°€ê²© ì¶”ì²œ</h1>", unsafe_allow_html=True)

# ì˜µì…˜ (í•™ìŠµ ë•Œ ì‚¬ìš©í•œ ìˆœì„œì™€ ë™ì¼í•´ì•¼ í•¨)
condition_options = ['ìƒˆ ìƒí’ˆ', 'ê±°ì˜ ìƒˆ ê²ƒ', 'ì‚¬ìš©ê° ìˆìŒ']
city_options = [
    'ì„œìš¸íŠ¹ë³„ì‹œ','ë¶€ì‚°ê´‘ì—­ì‹œ','ê²½ê¸°ë„','ì¸ì²œê´‘ì—­ì‹œ','ëŒ€êµ¬ê´‘ì—­ì‹œ',
    'ëŒ€ì „ê´‘ì—­ì‹œ','ê´‘ì£¼ê´‘ì—­ì‹œ','ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ','ìš¸ì‚°ê´‘ì—­ì‹œ','ì œì£¼íŠ¹ë³„ìì¹˜ë„'
]
model_options = ['yoyo','explori','trailz','beat','crusi','scoot']
model_type_options = ['ì ˆì¶©í˜•','ë””ëŸ­ìŠ¤']

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
st.markdown("<div>ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”</div>", unsafe_allow_html=True)
uploaded = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”", type=["jpg", "jpeg", "png"], label_visibility="collapsed")
if uploaded is not None:
    st.image(uploaded, use_column_width=True, caption="ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°")

st.divider()

# ì…ë ¥ UI
col = st.container()
with col:
    condition = st.selectbox("ì‚¬ìš©ê°", condition_options, index=2, key="condition")
    city = st.selectbox('ë„ì‹œëª…', city_options, index=9, key="location")
    model_name = st.selectbox('ëª¨ë¸ëª…', model_options, index=4, key="model")
    model_type = st.selectbox('ëª¨ë¸ ë“±ê¸‰', model_type_options, index=1, key="model_type")

# ëª¨ë¸ ì •ì˜ (í•™ìŠµ êµ¬ì¡°ì™€ ë™ì¼)
class CombinedModel(nn.Module):
    """
    ConvNeXt-Small image + csv -> íšŒê·€ ì¶œë ¥(ê°€ê²©)
    """
    def __init__(self, tabular_data_size, backbone, img_dim=64, tab_dim=256, tab_scale=1.0, img_scale=1.0):
        super().__init__()
        self.tab_scale = tab_scale
        self.img_scale = img_scale
        self.conv_part = backbone

        with torch.no_grad():
            dummy = torch.randn(1, 3, 224, 224)
            out = self.conv_part(dummy)
            conv_out_dim = out.shape[-1] if out.ndim == 2 else out.numel()

        self.img_head = nn.Sequential(nn.Linear(conv_out_dim, img_dim), nn.ReLU())
        self.tab_head = nn.Sequential(nn.Linear(tabular_data_size, tab_dim), nn.ReLU())

        combined_features_size = img_dim + tab_dim
        
        self.reg_part = nn.Sequential(
            nn.Linear(combined_features_size, 512), nn.ReLU(),
            nn.Linear(512, 128), nn.ReLU(),
            nn.Linear(128, 1)
        )

    def forward(self, images, tabular_data):
        image_features = self.conv_part(images) * self.img_scale
        tab_features   = tabular_data * self.tab_scale
        image_features = self.img_head(image_features)   
        tab_features   = self.tab_head(tab_features)     
        combined = torch.cat([image_features, tab_features], dim=1)
        
        return self.reg_part(combined)                   

WEIGHT_PATH = "../training/model/convnext_best.pt"

def _extract_state_dict(obj):
    if isinstance(obj, dict):
        if "state_dict" in obj and isinstance(obj["state_dict"], dict):
            return obj["state_dict"]
        
        for k in ["model_state_dict", "net", "model"]:
            if k in obj and isinstance(obj[k], dict):
                return obj[k]
            
    return obj  

def _strip_module_prefix(state):
    if not isinstance(state, dict):
        return state
    
    need_strip = any(k.startswith("module.") for k in state.keys())
    
    if not need_strip:
        return state
    
    return {k.replace("module.", "", 1): v for k, v in state.items()}

@st.cache_resource(show_spinner=False)
def load_model_and_preprocess(weight_path: str = WEIGHT_PATH):
    # 1) ì²´í¬í¬ì¸íŠ¸ ì½ê¸°
    try:
        raw = torch.load(weight_path, map_location="cpu")
    except Exception as e:
        st.error(f"ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.stop()

    state = _extract_state_dict(raw)
    state = _strip_module_prefix(state)

    # 2) ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê¸°ëŒ€ ì°¨ì› ì½ê¸°
    try:
        img_dim_from_ckpt = state["img_head.0.weight"].shape[0]   
        tab_size_from_ckpt = state["tab_head.0.weight"].shape[1]  
    except Exception as e:
        st.error(f"ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë ˆì´ì–´ ëª¨ì–‘ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.stop()

    # 3) ë°±ë³¸ & ì „ì²˜ë¦¬
    weights = models.ConvNeXt_Small_Weights.DEFAULT
    backbone = models.convnext_small(weights=weights)
    backbone.classifier[2] = nn.Identity()
    backbone.eval()
    preprocess = weights.transforms()

    # 4) ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ (ì²´í¬í¬ì¸íŠ¸ ëª¨ì–‘ì— ë§ì¶”ê¸°)
    model = CombinedModel(
        tabular_data_size=tab_size_from_ckpt,
        backbone=backbone,
        img_dim=img_dim_from_ckpt,   # ex) 32
        tab_dim=256
    )
    model.eval()

    # 5) ê°€ì¤‘ì¹˜ ë¡œë“œ(ëª¨ì–‘ì´ ì´ë¯¸ ë§ì•„ì„œ strict=True ê°€ëŠ¥)
    try:
        model.load_state_dict(state, strict=True)
    except Exception as e:
        st.error(f"ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    return model, preprocess, tab_size_from_ckpt

model, preprocess, TAB_EXPECT = load_model_and_preprocess()


# íƒ­ ì¸ì½”ë”© (ì²´í¬í¬ì¸íŠ¸ ê¸°ëŒ€ í¬ê¸°ì— ë§ì¶¤)
def build_tab_tensor(condition, city, model_name, model_type, expected_size: int):
    c_idx = condition_options.index(condition)
    s_idx = city_options.index(city)
    m_idx = model_options.index(model_name)
    t_idx = model_type_options.index(model_type)

    if expected_size == 21:
        vec = []
        # condition (3)
        for opt in condition_options: vec.append(1.0 if condition==opt else 0.0)
        # city (10)
        for opt in city_options: vec.append(1.0 if city==opt else 0.0)
        # model (6)
        for opt in model_options: vec.append(1.0 if model_name==opt else 0.0)
        # model_type (2)
        for opt in model_type_options: vec.append(1.0 if model_type==opt else 0.0)
        return torch.tensor(vec, dtype=torch.float32).unsqueeze(0)

    elif expected_size in (4, 5):
        vec = [float(c_idx), float(s_idx), float(m_idx), float(t_idx)]
        if expected_size == 5:
            vec.append(1.0)  
        return torch.tensor(vec, dtype=torch.float32).unsqueeze(0)

    else:
        st.error(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” íƒ­ ì…ë ¥ í¬ê¸°ì…ë‹ˆë‹¤: {expected_size}")
        st.stop()

def save_uploaded_image(file):
    os.makedirs("sent_data", exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    path = f"sent_data/{ts}.jpg"
    Image.open(file).convert("RGB").save(path)
    return path

# ë²„íŠ¼ & ì¶”ë¡ 
clicked = st.button("ê°€ê²© ì˜ˆì¸¡í•˜ê¸°")

if clicked:
    if uploaded is None:
        st.warning("ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.stop()

    with st.spinner("ğŸ”® ëª¨ë¸ì´ ê°€ê²©ì„ ì˜ˆì¸¡ ì¤‘ì…ë‹ˆë‹¤..."):
        saved_path = save_uploaded_image(uploaded)

        image = Image.open(uploaded).convert("RGB")
        img_tensor = preprocess(image).unsqueeze(0)  # (1,3,224,224)
        tab_tensor = build_tab_tensor(condition, city, model_name, model_type, expected_size=TAB_EXPECT)

        with torch.no_grad():
            pred = model(img_tensor, tab_tensor).squeeze().item()

        rec_price = max(0, round(float(pred)))
        time.sleep(0.4)

    st.success("ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ âœ…")
    st.markdown("<div>", unsafe_allow_html=True)
    st.markdown("<h3>ê²°ê³¼</h3>", unsafe_allow_html=True)

    c1, c2 = st.columns([1, 2.2])
    with c1:
        st.markdown("**ì¶”ì²œ ê°€ê²©**")
    with c2:
        st.text_input("ì¶”ì²œ ê°€ê²©", f"{rec_price:,} ì›", key="predict_price", disabled=True, label_visibility="collapsed")

    st.caption(f"ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: {saved_path}")
else:
    st.markdown(
        """
        <div class="card">
            <h3>ê²°ê³¼</h3>
            <p>ì…ë ¥ í›„ <b>ê°€ê²© ì˜ˆì¸¡í•˜ê¸°</b> ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.</p>
        </div>
        """,
        unsafe_allow_html=True
    )
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb66147",
   "metadata": {},
   "source": [
    "# Clean 데이터 학습\n",
    "## 결측치가 없는(모델, 상태, 지역 정보가 모두 있는) 데이터로 회귀 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba30282",
   "metadata": {},
   "source": [
    "### 0. 의존성 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84154f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, math, warnings, random\n",
    "from typing import List\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8549e81d",
   "metadata": {},
   "source": [
    "### 1. 결측치가 없는 데이터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb83dbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 5127\n",
      "After: 1391\n",
      "model        0\n",
      "condition    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CSV 로드\n",
    "CSV_PATH = \"../../csv/data_0826.csv\"\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# 제거 대상 컬럼 지정\n",
    "required_cols = [\"model\", \"condition\"]\n",
    "\n",
    "# 결측치 제거 전 행 수\n",
    "print(\"Before:\", len(df))\n",
    "\n",
    "# 해당 컬럼들 중 하나라도 결측치(NaN)이면 제거\n",
    "df = df.dropna(subset=required_cols)\n",
    "\n",
    "# 결측치 제거 후 행 수\n",
    "print(\"After:\", len(df))\n",
    "\n",
    "# 확인\n",
    "print(df[required_cols].isna().sum())\n",
    "\n",
    "# clean data 다시 저장\n",
    "df.to_csv(\"../../csv/data_regression_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32117176",
   "metadata": {},
   "source": [
    "### 2. 데이터 벡터화(첫번째 이미지 + 모델 + 모델 등급 + 상태 + 지역) 하여 train set / test set 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38359aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[임베딩] 200/1391\n",
      "[임베딩] 400/1391\n",
      "[임베딩] 600/1391\n",
      "[임베딩] 800/1391\n",
      "[임베딩] 1000/1391\n",
      "[임베딩] 1200/1391\n",
      "원핫 feature 수: 52\n",
      "이미지 feature 수: 512\n",
      "총 feature 수   : 564\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# pip install torch torchvision pandas pillow numpy scikit-learn pyarrow\n",
    "import os, glob, warnings\n",
    "from typing import Optional\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# ========= 사용자 설정 =========\n",
    "CSV_PATH   = \"../../csv/data_regression_clean.csv\"   # CSV: id, location, model, model_type, condition\n",
    "IMG_ROOT   = \"../../data/regression_clean_images\"    # 각 id 폴더가 존재\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# ========= 530×690으로 자르는 함수 =========\n",
    "def make_rect_530x690(img: Image.Image) -> Image.Image:\n",
    "    \"\"\"\n",
    "    입력 이미지 -> 중앙 크롭으로 타깃 비율(530:690) 맞춘 뒤, 정확히 530×690으로 리사이즈.\n",
    "    * 왜 중앙 크롭? 패딩보다 왜곡/여백 없이 정보 밀도를 유지하기 쉬움.\n",
    "    \"\"\"\n",
    "    img = ImageOps.exif_transpose(img)  # EXIF 회전 보정\n",
    "    w, h = img.size\n",
    "    target_w, target_h = 530, 690\n",
    "    target_ratio = target_w / target_h   # ≈ 0.768 (세로가 더 긴 비율)\n",
    "    cur_ratio = w / h\n",
    "\n",
    "    if cur_ratio > target_ratio:\n",
    "        # 현재가 더 가로로 넓음 → 가로를 잘라서 비율 맞추기\n",
    "        new_w = int(h * target_ratio)\n",
    "        left  = (w - new_w) // 2\n",
    "        img = img.crop((left, 0, left + new_w, h))\n",
    "    elif cur_ratio < target_ratio:\n",
    "        # 현재가 더 세로로 김 → 세로를 잘라서 비율 맞추기\n",
    "        new_h = int(w / target_ratio)\n",
    "        top   = (h - new_h) // 2\n",
    "        img = img.crop((0, top, w, top + new_h))\n",
    "    # 이제 비율이 타깃과 동일 → 정확히 530×690으로 리사이즈\n",
    "    return img.resize((target_w, target_h), Image.BICUBIC)\n",
    "\n",
    "# ========= 임베딩용 전처리 =========\n",
    "# 1) 530×690으로 맞춤(위 함수)\n",
    "tfm = transforms.Compose([\n",
    "    transforms.Lambda(lambda im: make_rect_530x690(im)),\n",
    "    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC, antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# ========= 임베딩 모델 준비(ResNet18, FC 제거) =========\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "feature_dim = resnet.fc.in_features  # 512\n",
    "resnet.fc = nn.Identity()            # 분류기 제거 → 512차 임베딩\n",
    "resnet.eval().to(device)\n",
    "\n",
    "# ========= 폴더 첫 이미지 선택 & 임베딩 =========\n",
    "IMG_EXTS = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "def first_image_path(folder: str) -> Optional[str]:\n",
    "    if not os.path.isdir(folder):\n",
    "        return None\n",
    "    paths = []\n",
    "    for ext in IMG_EXTS:\n",
    "        paths += glob.glob(os.path.join(folder, f\"*{ext}\"))\n",
    "        paths += glob.glob(os.path.join(folder, f\"*{ext.upper()}\"))\n",
    "    if not paths:\n",
    "        return None\n",
    "    return sorted(set(paths))[0]\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_first_image(path: Optional[str]) -> np.ndarray:\n",
    "    if path is None:\n",
    "        return np.zeros(feature_dim, dtype=np.float32)\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "    except Exception:\n",
    "        return np.zeros(feature_dim, dtype=np.float32)\n",
    "    x = tfm(im).unsqueeze(0).to(device)        # (1,3,224,224)\n",
    "    feat = resnet(x).squeeze(0).cpu().numpy()  # (512,)\n",
    "    return feat.astype(np.float32)\n",
    "\n",
    "# 모든 id에 대해: 폴더의 첫 이미지 1장만 임베딩\n",
    "ids = df[\"id\"].astype(str).tolist()\n",
    "img_feats = []\n",
    "for i, item_id in enumerate(ids, 1):\n",
    "    p0 = first_image_path(os.path.join(IMG_ROOT, item_id))\n",
    "    img_feats.append(embed_first_image(p0))\n",
    "    if i % 200 == 0:\n",
    "        print(f\"[임베딩] {i}/{len(ids)}\")\n",
    "\n",
    "img_feats = np.vstack(img_feats)                # (N, 512)\n",
    "img_cols = [f\"img_{k}\" for k in range(img_feats.shape[1])]\n",
    "df_img = pd.DataFrame(img_feats, columns=img_cols)\n",
    "\n",
    "# ========= 벡터 결합: (원핫 4컬럼) + (이미지512) =========\n",
    "df_vec = pd.concat([df.reset_index(drop=True), df_img], axis=1)\n",
    "\n",
    "cat_cols = [\"location\", \"model\", \"model_type\", \"condition\"]\n",
    "for c in cat_cols:\n",
    "    df_vec[c] = df_vec[c].astype(str).str.strip()  # 간단 정규화\n",
    "\n",
    "X_cat = pd.get_dummies(df_vec[cat_cols], drop_first=False)\n",
    "X_img = df_vec[img_cols]\n",
    "X_all = pd.concat([X_cat, X_img], axis=1)\n",
    "\n",
    "print(\"원핫 feature 수:\", X_cat.shape[1])\n",
    "print(\"이미지 feature 수:\", X_img.shape[1])     # 512\n",
    "print(\"총 feature 수   :\", X_all.shape[1])      # 564 = 원핫 + 512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c144f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1112, 564) X_test: (279, 564)\n",
      "[Eval] MAE=118,127.42 | RMSE=208,631.71 | R²=0.2294\n",
      "[Baseline: 평균] RMSE=613,777.48 | R²=-5.6690\n",
      "저장 완료: price_regressor_hgbr.joblib\n"
     ]
    }
   ],
   "source": [
    "# ========= 4) Train / Test split & 학습/평가 (HGBR + log 타깃) =========\n",
    "import numpy as np, math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# 안전체크: price 컬럼 존재\n",
    "if \"price\" not in df_vec.columns:\n",
    "    raise ValueError(\"CSV에 'price' 컬럼이 필요합니다. df_vec에 price가 없습니다.\")\n",
    "\n",
    "# 입력/타깃 준비\n",
    "X = X_all.values.astype(np.float32)              # (N, D)\n",
    "y = df_vec[\"price\"].astype(float).values         # (N,)\n",
    "\n",
    "# 학습/검증 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "\n",
    "# 모델: 트리 계열 회귀 + 로그 타깃 감싸기(스케일 안정화)\n",
    "base_reg = HistGradientBoostingRegressor(\n",
    "    learning_rate=0.08,\n",
    "    max_leaf_nodes=31,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "model = TransformedTargetRegressor(\n",
    "    regressor=base_reg,\n",
    "    func=np.log1p,        # y -> log1p(y)로 학습\n",
    "    inverse_func=np.expm1 # 예측을 원래 스케일로 복원\n",
    ")\n",
    "\n",
    "# 학습\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 & 평가\n",
    "pred = model.predict(X_test)\n",
    "mae  = mean_absolute_error(y_test, pred)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, pred))\n",
    "r2   = r2_score(y_test, pred)\n",
    "\n",
    "print(f\"[Eval] MAE={mae:,.2f} | RMSE={rmse:,.2f} | R²={r2:.4f}\")\n",
    "\n",
    "# (선택) 단순 평균 예측과 비교해 보기 (baseline)\n",
    "y_mean_pred = np.full_like(y_test, y_train.mean(), dtype=float)\n",
    "rmse_mean = math.sqrt(mean_squared_error(y_test, y_mean_pred))\n",
    "r2_mean   = r2_score(y_test, y_mean_pred)\n",
    "print(f\"[Baseline: 평균] RMSE={rmse_mean:,.2f} | R²={r2_mean:.4f}\")  # R²는 항상 0.0 근처\n",
    "\n",
    "# (선택) 모델 저장 - scikit-learn은 .joblib 권장\n",
    "joblib.dump(model, \"price_regressor_hgbr.joblib\")\n",
    "print(\"저장 완료: price_regressor_hgbr.joblib\")\n",
    "\n",
    "# (선택) 로드/사용 예시\n",
    "# loaded = joblib.load(\"price_regressor_hgbr.joblib\")\n",
    "# y_pred = loaded.predict(X_test[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1256e79",
   "metadata": {},
   "source": [
    "### 3. AUTO ML 및 Optuna을 통해 모델 추천 및 하이퍼 파라미터 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e660e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51c45fae5f3479fac98efa1c9ab4abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====== AutoML: LazyRegressor ======\n",
    "lzr = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None, random_state=42)\n",
    "models_df, preds_df = lzr.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# 성능표 확인 (RMSE/MAE/R2 등). 상위 10개만 보기\n",
    "print(models_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96896e69",
   "metadata": {},
   "source": [
    "### 4. 벡터화된 데이터로 추천 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n",
      "[01] loss=374563173588081.7500 | Train RMSE=19353632.51 R2=-0.002 | Val RMSE=269349.38 R2=-0.860\n",
      "[02] loss=374563004046904.8750 | Train RMSE=19353624.71 R2=-0.002 | Val RMSE=269252.85 R2=-0.859\n",
      "[03] loss=374562681069171.6250 | Train RMSE=19353616.90 R2=-0.002 | Val RMSE=269097.77 R2=-0.857\n",
      "[04] loss=374562264847921.5625 | Train RMSE=19353603.90 R2=-0.002 | Val RMSE=268857.79 R2=-0.854\n",
      "[05] loss=374561713573858.6250 | Train RMSE=19353581.36 R2=-0.002 | Val RMSE=268495.03 R2=-0.849\n",
      "[06] loss=374560827935637.5625 | Train RMSE=19353552.76 R2=-0.002 | Val RMSE=268022.85 R2=-0.842\n",
      "[07] loss=374559506068968.1250 | Train RMSE=19353517.21 R2=-0.002 | Val RMSE=267422.88 R2=-0.834\n",
      "[08] loss=374557996616715.0000 | Train RMSE=19353460.87 R2=-0.002 | Val RMSE=266507.16 R2=-0.821\n",
      "[09] loss=374556140479976.1250 | Train RMSE=19353394.98 R2=-0.002 | Val RMSE=265393.96 R2=-0.806\n",
      "[10] loss=374553125522677.9375 | Train RMSE=19353315.23 R2=-0.002 | Val RMSE=264037.35 R2=-0.788\n",
      "[11] loss=374549900398518.6250 | Train RMSE=19353222.47 R2=-0.002 | Val RMSE=262533.37 R2=-0.767\n",
      "[12] loss=374546193928661.8125 | Train RMSE=19353099.37 R2=-0.002 | Val RMSE=260466.51 R2=-0.740\n",
      "[13] loss=374540517602087.4375 | Train RMSE=19353015.28 R2=-0.002 | Val RMSE=259080.89 R2=-0.721\n",
      "[14] loss=374534887452114.1250 | Train RMSE=19352861.84 R2=-0.002 | Val RMSE=256588.90 R2=-0.688\n",
      "[15] loss=374530462554750.6250 | Train RMSE=19352611.30 R2=-0.001 | Val RMSE=252614.93 R2=-0.636\n",
      "[16] loss=374521411138196.6250 | Train RMSE=19352409.31 R2=-0.001 | Val RMSE=249420.37 R2=-0.595\n",
      "[17] loss=374511253779371.5625 | Train RMSE=19352241.99 R2=-0.001 | Val RMSE=246771.17 R2=-0.562\n",
      "[18] loss=374504998471437.7500 | Train RMSE=19351932.49 R2=-0.001 | Val RMSE=242084.36 R2=-0.503\n",
      "[19] loss=374494453050966.2500 | Train RMSE=19351612.58 R2=-0.001 | Val RMSE=237449.31 R2=-0.446\n",
      "[20] loss=374481289727544.8750 | Train RMSE=19351369.83 R2=-0.001 | Val RMSE=233984.21 R2=-0.404\n",
      "가중치 저장 완료: price_regressor_best.pth / price_regressor.pth\n"
     ]
    }
   ],
   "source": [
    "# ========= 4) PyTorch Dataset/Dataloader =========\n",
    "class TabImageDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X)  # float32\n",
    "        self.y = torch.from_numpy(y).view(-1, 1)  # (N, 1)\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds = TabImageDS(X_train, y_train)\n",
    "test_ds  = TabImageDS(X_test,  y_test)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ========= 5) 간단한 MLP 회귀 모델 =========\n",
    "in_dim = X_all.shape[1]\n",
    "class PriceRegressor(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = PriceRegressor(in_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ========= 6) 학습 루프 =========\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    preds, gts = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            preds.append(out.squeeze(1).cpu().numpy())\n",
    "            gts.append(yb.squeeze(1).cpu().numpy())\n",
    "    preds = np.concatenate(preds)\n",
    "    gts   = np.concatenate(gts)\n",
    "    mae  = mean_absolute_error(gts, preds)\n",
    "    rmse = math.sqrt(((gts - preds) ** 2).mean())\n",
    "    r2   = r2_score(gts, preds)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(                                            asdasdasdasdaddaasdasdadsdasdssssxb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_mae, train_rmse, train_r2 = evaluate(train_loader)\n",
    "    val_mae,   val_rmse,   val_r2   = evaluate(test_loader)\n",
    "    print(f\"[{epoch:02d}] loss={total_loss/len(train_ds):.4f} \"\n",
    "        f\"| Train RMSE={train_rmse:.2f} R2={train_r2:.3f} \"\n",
    "        f\"| Val RMSE={val_rmse:.2f} R2={val_r2:.3f}\")\n",
    "\n",
    "    # 간단한 베스트 체크(검증 RMSE 개선 시 가중치 임시 저장)\n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        torch.save(model.state_dict(), \"price_regressor_best.pth\")\n",
    "\n",
    "# 마지막 에폭 가중치도 저장(원하면 둘 중 하나만 쓰면 됨)\n",
    "torch.save(model.state_dict(), \"price_regressor.pth\")\n",
    "print(\"가중치 저장 완료: price_regressor_best.pth / price_regressor.pth\")\n",
    "\n",
    "# ========= 7) 로드 방법(예시) =========\n",
    "# model = PriceRegressor(in_dim)\n",
    "# model.load_state_dict(torch.load(\"price_regressor_best.pth\", map_location=\"cpu\"))\n",
    "# model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SecondHanded-Strollers-PredictedPrice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
